{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "Y0fOWhqwW-AT",
        "outputId": "317f4680-6f82-428e-c95a-d3e99fbc011a",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:48:12.152592Z",
          "iopub.execute_input": "2021-12-21T10:48:12.152940Z",
          "iopub.status.idle": "2021-12-21T10:49:03.802506Z",
          "shell.execute_reply.started": "2021-12-21T10:48:12.152854Z",
          "shell.execute_reply": "2021-12-21T10:49:03.801719Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "u3wugeOHW-AV",
        "outputId": "db808518-7ab6-4e48-9be0-30f216dbd9b0",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:03.806090Z",
          "iopub.execute_input": "2021-12-21T10:49:03.806305Z",
          "iopub.status.idle": "2021-12-21T10:49:05.532212Z",
          "shell.execute_reply.started": "2021-12-21T10:49:03.806280Z",
          "shell.execute_reply": "2021-12-21T10:49:05.531429Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Скачиваем данные"
      ],
      "metadata": {
        "id": "m9XIrxSmW-AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ],
      "metadata": {
        "id": "ep1FB3IBW-AY",
        "outputId": "af1b4554-404a-487e-883e-9c1ddee4bbde",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:05.534819Z",
          "iopub.execute_input": "2021-12-21T10:49:05.535089Z",
          "iopub.status.idle": "2021-12-21T10:49:07.817871Z",
          "shell.execute_reply.started": "2021-12-21T10:49:05.535057Z",
          "shell.execute_reply": "2021-12-21T10:49:07.816962Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 12:00:43--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M   143MB/s    in 0.2s    \n",
            "\n",
            "2021-12-21 12:00:43 (143 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ],
      "metadata": {
        "id": "BWA7IClKW-Aa",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:07.819633Z",
          "iopub.execute_input": "2021-12-21T10:49:07.819934Z",
          "iopub.status.idle": "2021-12-21T10:49:07.823919Z",
          "shell.execute_reply.started": "2021-12-21T10:49:07.819894Z",
          "shell.execute_reply": "2021-12-21T10:49:07.823138Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "id": "qJpFTPpsW-Ac",
        "outputId": "4032e7a9-3453-4366-e6ea-2910bb6edd12",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:07.827147Z",
          "iopub.execute_input": "2021-12-21T10:49:07.827407Z",
          "iopub.status.idle": "2021-12-21T10:49:08.495458Z",
          "shell.execute_reply.started": "2021-12-21T10:49:07.827373Z",
          "shell.execute_reply": "2021-12-21T10:49:08.494702Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Dec 21 12:00 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qmzaEwy9W-Ae",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:08.498381Z",
          "iopub.execute_input": "2021-12-21T10:49:08.498603Z",
          "iopub.status.idle": "2021-12-21T10:49:08.504623Z",
          "shell.execute_reply.started": "2021-12-21T10:49:08.498577Z",
          "shell.execute_reply": "2021-12-21T10:49:08.503936Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ],
      "metadata": {
        "id": "BbDKxq4EW-Ag",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:08.506060Z",
          "iopub.execute_input": "2021-12-21T10:49:08.506436Z",
          "iopub.status.idle": "2021-12-21T10:49:09.085036Z",
          "shell.execute_reply.started": "2021-12-21T10:49:08.506400Z",
          "shell.execute_reply": "2021-12-21T10:49:09.084296Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "hcAdsbS7W-Ai",
        "outputId": "a349ea54-238e-4a43-89b1-ac544e98a7f1",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:09.086234Z",
          "iopub.execute_input": "2021-12-21T10:49:09.086948Z",
          "iopub.status.idle": "2021-12-21T10:49:09.106018Z",
          "shell.execute_reply.started": "2021-12-21T10:49:09.086910Z",
          "shell.execute_reply": "2021-12-21T10:49:09.105240Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b38d982a-eec9-4a88-a858-f99f0178c38e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b38d982a-eec9-4a88-a858-f99f0178c38e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b38d982a-eec9-4a88-a858-f99f0178c38e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b38d982a-eec9-4a88-a858-f99f0178c38e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ],
      "metadata": {
        "id": "90tXLjfsW-Aj",
        "outputId": "669dc304-b0eb-4990-9fc5-b437d6f24125",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:09.107328Z",
          "iopub.execute_input": "2021-12-21T10:49:09.107643Z",
          "iopub.status.idle": "2021-12-21T10:49:09.144516Z",
          "shell.execute_reply.started": "2021-12-21T10:49:09.107607Z",
          "shell.execute_reply": "2021-12-21T10:49:09.143697Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ],
      "metadata": {
        "id": "gfHbifWIW-Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ],
      "metadata": {
        "id": "PVhCzM3LW-Al",
        "outputId": "7df43b61-3932-4baa-d2e3-f192da73e4fa",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:49:09.145986Z",
          "iopub.execute_input": "2021-12-21T10:49:09.146242Z",
          "iopub.status.idle": "2021-12-21T10:50:13.027632Z",
          "shell.execute_reply.started": "2021-12-21T10:49:09.146208Z",
          "shell.execute_reply": "2021-12-21T10:50:13.026702Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 12:00:44--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  33.1MB/s    in 44s     \n",
            "\n",
            "2021-12-21 12:01:29 (28.4 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "id": "eJcT1qPZW-An",
        "outputId": "f82cad31-d407-40eb-9606-548b0008ccb2",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:13.029343Z",
          "iopub.execute_input": "2021-12-21T10:50:13.029618Z",
          "iopub.status.idle": "2021-12-21T10:50:13.723140Z",
          "shell.execute_reply.started": "2021-12-21T10:50:13.029580Z",
          "shell.execute_reply": "2021-12-21T10:50:13.722212Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Dec 21 12:00 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "M0lwyZUFW-Ap",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:13.725149Z",
          "iopub.execute_input": "2021-12-21T10:50:13.725453Z",
          "iopub.status.idle": "2021-12-21T10:50:18.897998Z",
          "shell.execute_reply.started": "2021-12-21T10:50:13.725406Z",
          "shell.execute_reply": "2021-12-21T10:50:18.896943Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ],
      "metadata": {
        "id": "QQpX51Y4W-Aq",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:18.899644Z",
          "iopub.execute_input": "2021-12-21T10:50:18.900253Z",
          "iopub.status.idle": "2021-12-21T10:50:24.319488Z",
          "shell.execute_reply.started": "2021-12-21T10:50:18.900214Z",
          "shell.execute_reply": "2021-12-21T10:50:24.318530Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ],
      "metadata": {
        "id": "HyI2erCDW-Ar",
        "outputId": "c5330207-691f-46cb-8c9f-429659e1ebc6",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:24.328173Z",
          "iopub.execute_input": "2021-12-21T10:50:24.330474Z",
          "iopub.status.idle": "2021-12-21T10:50:27.399646Z",
          "shell.execute_reply.started": "2021-12-21T10:50:24.330428Z",
          "shell.execute_reply": "2021-12-21T10:50:27.398949Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:03<00:00, 74668.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "FGzDm0ptW-At",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:27.400835Z",
          "iopub.execute_input": "2021-12-21T10:50:27.401323Z",
          "iopub.status.idle": "2021-12-21T10:50:27.521443Z",
          "shell.execute_reply.started": "2021-12-21T10:50:27.401283Z",
          "shell.execute_reply": "2021-12-21T10:50:27.520695Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ],
      "metadata": {
        "id": "iZBR-aYDW-Av",
        "outputId": "1fb703c0-9ea9-46f5-cb74-89bd6bf1f16e",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:27.522594Z",
          "iopub.execute_input": "2021-12-21T10:50:27.523358Z",
          "iopub.status.idle": "2021-12-21T10:50:30.459376Z",
          "shell.execute_reply.started": "2021-12-21T10:50:27.523310Z",
          "shell.execute_reply": "2021-12-21T10:50:30.458540Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efedf6ceed0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ],
      "metadata": {
        "id": "OBzmPqXIW-Aw",
        "outputId": "d82f7294-8a53-4b1c-ae57-ff23b526993a",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:30.460790Z",
          "iopub.execute_input": "2021-12-21T10:50:30.461036Z",
          "iopub.status.idle": "2021-12-21T10:50:30.489423Z",
          "shell.execute_reply.started": "2021-12-21T10:50:30.461002Z",
          "shell.execute_reply": "2021-12-21T10:50:30.488726Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2freq)"
      ],
      "metadata": {
        "id": "GbSer_0bW-Ay",
        "outputId": "020a78ea-a283-4421-b7de-243a52950ed4",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:30.490578Z",
          "iopub.execute_input": "2021-12-21T10:50:30.490982Z",
          "iopub.status.idle": "2021-12-21T10:50:30.734698Z",
          "shell.execute_reply.started": "2021-12-21T10:50:30.490945Z",
          "shell.execute_reply": "2021-12-21T10:50:30.733721Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ],
      "metadata": {
        "id": "szg6XD3EW-Az",
        "outputId": "72005e7c-2f59-448d-9149-0d8f3e764313",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:30.739667Z",
          "iopub.execute_input": "2021-12-21T10:50:30.741909Z",
          "iopub.status.idle": "2021-12-21T10:50:30.803194Z",
          "shell.execute_reply.started": "2021-12-21T10:50:30.741866Z",
          "shell.execute_reply": "2021-12-21T10:50:30.802538Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ],
      "metadata": {
        "id": "bZbOg0FqW-A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "T1Yx_qr-W-A2",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:30.804300Z",
          "iopub.execute_input": "2021-12-21T10:50:30.804541Z",
          "iopub.status.idle": "2021-12-21T10:50:30.811100Z",
          "shell.execute_reply.started": "2021-12-21T10:50:30.804504Z",
          "shell.execute_reply": "2021-12-21T10:50:30.810419Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ],
      "metadata": {
        "id": "BLEgfnaWW-A4",
        "outputId": "6f16a101-86a1-4b79-b3fd-5f7ef5ca3094",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:50:30.812442Z",
          "iopub.execute_input": "2021-12-21T10:50:30.813079Z",
          "iopub.status.idle": "2021-12-21T10:51:44.556455Z",
          "shell.execute_reply.started": "2021-12-21T10:50:30.813040Z",
          "shell.execute_reply": "2021-12-21T10:51:44.555714Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:13<00:00, 27097.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2index)"
      ],
      "metadata": {
        "id": "AYJMzgpnW-A7",
        "outputId": "5d4dfe27-0a97-4ec4-a046-7bb39b0c6a2e",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:44.558132Z",
          "iopub.execute_input": "2021-12-21T10:51:44.558420Z",
          "iopub.status.idle": "2021-12-21T10:51:44.563477Z",
          "shell.execute_reply.started": "2021-12-21T10:51:44.558381Z",
          "shell.execute_reply": "2021-12-21T10:51:44.562808Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ],
      "metadata": {
        "id": "KE06fafiW-A8",
        "outputId": "33be4337-9ea7-4d4c-cdac-6615b78da506",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:44.564810Z",
          "iopub.execute_input": "2021-12-21T10:51:44.565205Z",
          "iopub.status.idle": "2021-12-21T10:51:44.652761Z",
          "shell.execute_reply.started": "2021-12-21T10:51:44.565169Z",
          "shell.execute_reply": "2021-12-21T10:51:44.652067Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ],
      "metadata": {
        "id": "GFPNApUjW-A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_fo1fB6JW-A-",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:44.654114Z",
          "iopub.execute_input": "2021-12-21T10:51:44.654373Z",
          "iopub.status.idle": "2021-12-21T10:51:45.879963Z",
          "shell.execute_reply.started": "2021-12-21T10:51:44.654337Z",
          "shell.execute_reply": "2021-12-21T10:51:45.879200Z"
        },
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ],
      "metadata": {
        "id": "pEKAjCg3W-BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ],
      "metadata": {
        "id": "D19pDyQBW-BA",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:45.881272Z",
          "iopub.execute_input": "2021-12-21T10:51:45.881523Z",
          "iopub.status.idle": "2021-12-21T10:51:45.956100Z",
          "shell.execute_reply.started": "2021-12-21T10:51:45.881488Z",
          "shell.execute_reply": "2021-12-21T10:51:45.955409Z"
        },
        "trusted": true
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ],
      "metadata": {
        "id": "Yxsxr7edW-BB",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:45.957428Z",
          "iopub.execute_input": "2021-12-21T10:51:45.957690Z",
          "iopub.status.idle": "2021-12-21T10:51:45.990399Z",
          "shell.execute_reply.started": "2021-12-21T10:51:45.957640Z",
          "shell.execute_reply": "2021-12-21T10:51:45.989788Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ],
      "metadata": {
        "id": "TZy0lKr2W-BC",
        "outputId": "4d7ddf3d-869a-4508-c85a-4d7db7f4f2c6",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:45.991535Z",
          "iopub.execute_input": "2021-12-21T10:51:45.991857Z",
          "iopub.status.idle": "2021-12-21T10:51:50.505541Z",
          "shell.execute_reply.started": "2021-12-21T10:51:45.991820Z",
          "shell.execute_reply": "2021-12-21T10:51:50.504754Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 841 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# А что GPU?"
      ],
      "metadata": {
        "id": "s611e34SW-BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ],
      "metadata": {
        "id": "xjFlWdgtW-BE",
        "outputId": "4b0374af-ece7-4db1-e73d-184f5e10c2d4",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:50.506924Z",
          "iopub.execute_input": "2021-12-21T10:51:50.507339Z",
          "iopub.status.idle": "2021-12-21T10:51:50.553537Z",
          "shell.execute_reply.started": "2021-12-21T10:51:50.507300Z",
          "shell.execute_reply": "2021-12-21T10:51:50.552824Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ],
      "metadata": {
        "id": "jaMMD5CDW-BG",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:50.555175Z",
          "iopub.execute_input": "2021-12-21T10:51:50.555461Z",
          "iopub.status.idle": "2021-12-21T10:51:50.564011Z",
          "shell.execute_reply.started": "2021-12-21T10:51:50.555403Z",
          "shell.execute_reply": "2021-12-21T10:51:50.563264Z"
        },
        "trusted": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ],
      "metadata": {
        "id": "GeQCiSYdW-BH",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:50.565508Z",
          "iopub.execute_input": "2021-12-21T10:51:50.565806Z",
          "iopub.status.idle": "2021-12-21T10:51:52.946306Z",
          "shell.execute_reply.started": "2021-12-21T10:51:50.565770Z",
          "shell.execute_reply": "2021-12-21T10:51:52.945548Z"
        },
        "trusted": true
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ],
      "metadata": {
        "id": "S_qUdMcbW-BJ",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:52.947759Z",
          "iopub.execute_input": "2021-12-21T10:51:52.948005Z",
          "iopub.status.idle": "2021-12-21T10:51:53.616048Z",
          "shell.execute_reply.started": "2021-12-21T10:51:52.947971Z",
          "shell.execute_reply": "2021-12-21T10:51:53.615284Z"
        },
        "trusted": true
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ],
      "metadata": {
        "id": "hSUQmRgtW-BK",
        "outputId": "0f05aff2-8ffe-4d7a-e833-d7deb975af69",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:51:53.617499Z",
          "iopub.execute_input": "2021-12-21T10:51:53.617783Z",
          "iopub.status.idle": "2021-12-21T10:52:01.562189Z",
          "shell.execute_reply.started": "2021-12-21T10:51:53.617738Z",
          "shell.execute_reply": "2021-12-21T10:52:01.561362Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 28.1 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ],
      "metadata": {
        "id": "gPvqNWkQW-BM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ],
      "metadata": {
        "id": "FaPKGO5aW-BN",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:01.563419Z",
          "iopub.execute_input": "2021-12-21T10:52:01.563942Z",
          "iopub.status.idle": "2021-12-21T10:52:01.567647Z",
          "shell.execute_reply.started": "2021-12-21T10:52:01.563900Z",
          "shell.execute_reply": "2021-12-21T10:52:01.566814Z"
        },
        "trusted": true
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ],
      "metadata": {
        "id": "9NX5HHDOW-BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ],
      "metadata": {
        "id": "zKr22rklW-BP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ],
      "metadata": {
        "id": "Bny8SvCgW-BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ],
      "metadata": {
        "id": "vc-bLok2W-BQ",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:01.568738Z",
          "iopub.execute_input": "2021-12-21T10:52:01.569209Z",
          "iopub.status.idle": "2021-12-21T10:52:02.344906Z",
          "shell.execute_reply.started": "2021-12-21T10:52:01.569170Z",
          "shell.execute_reply": "2021-12-21T10:52:02.344183Z"
        },
        "trusted": true
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "id": "OHpit-1tW-BR",
        "outputId": "d00707f7-e508-4d5c-9cb4-2c8af5d8e166",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:02.345943Z",
          "iopub.execute_input": "2021-12-21T10:52:02.346292Z",
          "iopub.status.idle": "2021-12-21T10:52:02.360932Z",
          "shell.execute_reply.started": "2021-12-21T10:52:02.346260Z",
          "shell.execute_reply": "2021-12-21T10:52:02.360104Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ],
      "metadata": {
        "id": "ru_WzGSJW-BS",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:02.363989Z",
          "iopub.execute_input": "2021-12-21T10:52:02.364304Z",
          "iopub.status.idle": "2021-12-21T10:52:02.994544Z",
          "shell.execute_reply.started": "2021-12-21T10:52:02.364266Z",
          "shell.execute_reply": "2021-12-21T10:52:02.993566Z"
        },
        "trusted": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ],
      "metadata": {
        "id": "NHdBavTWW-BT",
        "outputId": "67909233-4faf-4b52-b9c7-143f02f06561",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:02.996206Z",
          "iopub.execute_input": "2021-12-21T10:52:02.996475Z",
          "iopub.status.idle": "2021-12-21T10:52:03.002509Z",
          "shell.execute_reply.started": "2021-12-21T10:52:02.996436Z",
          "shell.execute_reply": "2021-12-21T10:52:03.001724Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ],
      "metadata": {
        "id": "Rcxv55j7W-BV",
        "outputId": "b9daef92-1cae-4de1-8c67-a4237a2574bf",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.004314Z",
          "iopub.execute_input": "2021-12-21T10:52:03.004829Z",
          "iopub.status.idle": "2021-12-21T10:52:03.013215Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.004789Z",
          "shell.execute_reply": "2021-12-21T10:52:03.012396Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ],
      "metadata": {
        "id": "PmJt6cqkW-BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "TyM8Xl24W-BX",
        "outputId": "107b7cd6-12b0-4b2c-c348-e4ac85907514",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.014981Z",
          "iopub.execute_input": "2021-12-21T10:52:03.015281Z",
          "iopub.status.idle": "2021-12-21T10:52:03.021683Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.015247Z",
          "shell.execute_reply": "2021-12-21T10:52:03.020837Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ],
      "metadata": {
        "id": "grPNMjEZW-BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ],
      "metadata": {
        "id": "btJ-ApiOW-BY",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.023302Z",
          "iopub.execute_input": "2021-12-21T10:52:03.023620Z",
          "iopub.status.idle": "2021-12-21T10:52:03.042574Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.023587Z",
          "shell.execute_reply": "2021-12-21T10:52:03.041989Z"
        },
        "trusted": true
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ],
      "metadata": {
        "id": "QIYff7YyW-Bb",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.048562Z",
          "iopub.execute_input": "2021-12-21T10:52:03.049064Z",
          "iopub.status.idle": "2021-12-21T10:52:03.052721Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.049034Z",
          "shell.execute_reply": "2021-12-21T10:52:03.051839Z"
        },
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ],
      "metadata": {
        "id": "7tVn6YKLW-Bd",
        "outputId": "ddb89d9f-2541-419f-ca21-684ed1f38f69",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.053885Z",
          "iopub.execute_input": "2021-12-21T10:52:03.054717Z",
          "iopub.status.idle": "2021-12-21T10:52:03.063396Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.054653Z",
          "shell.execute_reply": "2021-12-21T10:52:03.062718Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ],
      "metadata": {
        "id": "2N4w6-iWW-Be",
        "outputId": "9b2aac17-7f3b-4800-d97e-813cd25fdec4",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.064560Z",
          "iopub.execute_input": "2021-12-21T10:52:03.064965Z",
          "iopub.status.idle": "2021-12-21T10:52:03.353957Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.064929Z",
          "shell.execute_reply": "2021-12-21T10:52:03.353276Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ],
      "metadata": {
        "id": "7-C3_phaW-Bf",
        "outputId": "7f39da62-c678-4ab4-bbae-77f4ee1a66e2",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.356542Z",
          "iopub.execute_input": "2021-12-21T10:52:03.356752Z",
          "iopub.status.idle": "2021-12-21T10:52:03.363595Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.356727Z",
          "shell.execute_reply": "2021-12-21T10:52:03.362705Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовим данные в DataLoader"
      ],
      "metadata": {
        "id": "stBQ3yhqW-Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "vPX_m5M4W-Bi",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.365204Z",
          "iopub.execute_input": "2021-12-21T10:52:03.365744Z",
          "iopub.status.idle": "2021-12-21T10:52:03.370886Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.365668Z",
          "shell.execute_reply": "2021-12-21T10:52:03.370183Z"
        },
        "trusted": true
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'UNK' in word2index"
      ],
      "metadata": {
        "id": "hV76BdN0W-Bj",
        "outputId": "044bc809-a241-470d-ade1-378b8c87cb4a",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.372212Z",
          "iopub.execute_input": "2021-12-21T10:52:03.372700Z",
          "iopub.status.idle": "2021-12-21T10:52:03.380884Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.372628Z",
          "shell.execute_reply": "2021-12-21T10:52:03.380104Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "INB_dPAnW-Bk",
        "outputId": "f4f1d0c4-8e77-4267-9bea-a2492e8c9374",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.382463Z",
          "iopub.execute_input": "2021-12-21T10:52:03.382792Z",
          "iopub.status.idle": "2021-12-21T10:52:03.394252Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.382760Z",
          "shell.execute_reply": "2021-12-21T10:52:03.393350Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c56c5629-66d5-4c00-b8fe-9c57bc68b648\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c56c5629-66d5-4c00-b8fe-9c57bc68b648')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c56c5629-66d5-4c00-b8fe-9c57bc68b648 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c56c5629-66d5-4c00-b8fe-9c57bc68b648');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замапим категории в индексы"
      ],
      "metadata": {
        "id": "1qv1mKAeW-Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ],
      "metadata": {
        "id": "iHeFzZe1W-Bl",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.395884Z",
          "iopub.execute_input": "2021-12-21T10:52:03.396140Z",
          "iopub.status.idle": "2021-12-21T10:52:03.420782Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.396108Z",
          "shell.execute_reply": "2021-12-21T10:52:03.420141Z"
        },
        "trusted": true
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_mapper"
      ],
      "metadata": {
        "id": "X3x9QhXYW-Bn",
        "outputId": "4168a958-7875-4d05-f4c1-1e9efcd76b61",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.421703Z",
          "iopub.execute_input": "2021-12-21T10:52:03.421931Z",
          "iopub.status.idle": "2021-12-21T10:52:03.427325Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.421900Z",
          "shell.execute_reply": "2021-12-21T10:52:03.426570Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'food': 4, 'law': 1, 'love': 2, 'relax': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ],
      "metadata": {
        "id": "ef--8SWbW-Bo",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.428476Z",
          "iopub.execute_input": "2021-12-21T10:52:03.428896Z",
          "iopub.status.idle": "2021-12-21T10:52:03.456126Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.428859Z",
          "shell.execute_reply": "2021-12-21T10:52:03.455487Z"
        },
        "trusted": true
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Читалка данных"
      ],
      "metadata": {
        "id": "vc48ALg_W-Bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ],
      "metadata": {
        "id": "WFIQEv6nvE4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ],
      "metadata": {
        "id": "ZkX8SC_sW-Bp",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.457423Z",
          "iopub.execute_input": "2021-12-21T10:52:03.457793Z",
          "iopub.status.idle": "2021-12-21T10:52:03.470004Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.457760Z",
          "shell.execute_reply": "2021-12-21T10:52:03.469374Z"
        },
        "trusted": true
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "R3WW8V9lyLm0",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.472581Z",
          "iopub.execute_input": "2021-12-21T10:52:03.472825Z",
          "iopub.status.idle": "2021-12-21T10:52:03.482258Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.472794Z",
          "shell.execute_reply": "2021-12-21T10:52:03.481526Z"
        },
        "trusted": true
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "Lnc2nD8gW-Br",
        "outputId": "926bc47f-b86b-41ac-f706-ccc61348c805",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:03.483686Z",
          "iopub.execute_input": "2021-12-21T10:52:03.484005Z",
          "iopub.status.idle": "2021-12-21T10:52:06.834709Z",
          "shell.execute_reply.started": "2021-12-21T10:52:03.483973Z",
          "shell.execute_reply": "2021-12-21T10:52:06.833885Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:03<00:00, 65648.04it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 68828.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ],
      "metadata": {
        "id": "dGeftxdgW-Br",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:06.836162Z",
          "iopub.execute_input": "2021-12-21T10:52:06.836427Z",
          "iopub.status.idle": "2021-12-21T10:52:06.847018Z",
          "shell.execute_reply.started": "2021-12-21T10:52:06.836389Z",
          "shell.execute_reply": "2021-12-21T10:52:06.846176Z"
        },
        "trusted": true
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "nNkGQffBW-Bs",
        "outputId": "a700eda8-c57e-41ce-fa1e-919c2540f28e",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:06.848485Z",
          "iopub.execute_input": "2021-12-21T10:52:06.848831Z",
          "iopub.status.idle": "2021-12-21T10:52:06.857360Z",
          "shell.execute_reply.started": "2021-12-21T10:52:06.848791Z",
          "shell.execute_reply": "2021-12-21T10:52:06.856506Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1653,    13,   867,  ...,     0,     0,     0],\n",
              "        [ 3989,    56,   137,  ...,     0,     0,     0],\n",
              "        [31299,  6668,   121,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [17320,   458,  1977,  ...,     0,     0,     0],\n",
              "        [   49, 14572,   330,  ...,     0,     0,     0],\n",
              "        [    8,   789,  5310,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "fxUk4nGcW-Bt",
        "outputId": "1770a97c-2fa9-4fb0-8df2-14cdc7605a95",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:06.859185Z",
          "iopub.execute_input": "2021-12-21T10:52:06.859821Z",
          "iopub.status.idle": "2021-12-21T10:52:06.866387Z",
          "shell.execute_reply.started": "2021-12-21T10:52:06.859783Z",
          "shell.execute_reply": "2021-12-21T10:52:06.865470Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 3, 0, 3, 3, 0, 3, 0, 0, 1, 2, 0, 0, 2, 0, 3, 1, 4, 3, 0, 1, 1,\n",
              "        3, 4, 4, 4, 1, 3, 0, 2, 1, 0, 2, 0, 4, 0, 4, 3, 0, 1, 3, 2, 0, 1, 4, 4,\n",
              "        0, 3, 4, 1, 0, 2, 1, 1, 0, 2, 1, 1, 2, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучить нейронку"
      ],
      "metadata": {
        "id": "Zy0dkkTIW-Bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "        \n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(300, 256, \n",
        "                                  num_layers=2, bidirectional=True, dropout=0.1,\n",
        "                                  batch_first=True)\n",
        "        \n",
        "        self.q_proj = torch.nn.Linear(in_features=2*256, out_features=256, bias=True)\n",
        "        self.k_proj = torch.nn.Linear(in_features=2*256, out_features=256, bias=True)\n",
        "        self.v_proj = torch.nn.Linear(in_features=2*256, out_features=256, bias=True)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        \n",
        "        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
        "        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "\n",
        "        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "        \n",
        "  def forward(self, x):\n",
        "      x_emb = self.emb_layer(x) #примените эмбеддинги\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) / sqrt(x_q.size(-1))\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      \n",
        "      x =  self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ],
      "metadata": {
        "id": "3wwkxZm1vE43",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:06.868085Z",
          "iopub.execute_input": "2021-12-21T10:52:06.868414Z",
          "iopub.status.idle": "2021-12-21T10:52:06.886097Z",
          "shell.execute_reply.started": "2021-12-21T10:52:06.868378Z",
          "shell.execute_reply": "2021-12-21T10:52:06.885376Z"
        },
        "trusted": true
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ],
      "metadata": {
        "id": "jFbyUXLE0WPv",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:06.887207Z",
          "iopub.execute_input": "2021-12-21T10:52:06.887868Z",
          "iopub.status.idle": "2021-12-21T10:52:06.900884Z",
          "shell.execute_reply.started": "2021-12-21T10:52:06.887828Z",
          "shell.execute_reply": "2021-12-21T10:52:06.900186Z"
        },
        "trusted": true
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_with_att(vectors, n_classes)"
      ],
      "metadata": {
        "id": "OZgh4ONx0HvT",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:06.902351Z",
          "iopub.execute_input": "2021-12-21T10:52:06.902919Z",
          "iopub.status.idle": "2021-12-21T10:52:07.043558Z",
          "shell.execute_reply.started": "2021-12-21T10:52:06.902871Z",
          "shell.execute_reply": "2021-12-21T10:52:07.042841Z"
        },
        "trusted": true
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ],
      "metadata": {
        "id": "CNO6VSbJgQ36",
        "outputId": "96f52123-3adb-48df-ca73-86368da84582",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:07.044929Z",
          "iopub.execute_input": "2021-12-21T10:52:07.045170Z",
          "iopub.status.idle": "2021-12-21T10:52:07.051323Z",
          "shell.execute_reply.started": "2021-12-21T10:52:07.045137Z",
          "shell.execute_reply": "2021-12-21T10:52:07.050625Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ],
      "metadata": {
        "id": "E66MWNgM0QKM",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:07.052622Z",
          "iopub.execute_input": "2021-12-21T10:52:07.053081Z",
          "iopub.status.idle": "2021-12-21T10:52:07.245582Z",
          "shell.execute_reply.started": "2021-12-21T10:52:07.053010Z",
          "shell.execute_reply": "2021-12-21T10:52:07.244808Z"
        },
        "trusted": true
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "id": "ErboeQbv0dnC",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:07.247703Z",
          "iopub.execute_input": "2021-12-21T10:52:07.248215Z",
          "iopub.status.idle": "2021-12-21T10:52:07.255221Z",
          "shell.execute_reply.started": "2021-12-21T10:52:07.248176Z",
          "shell.execute_reply": "2021-12-21T10:52:07.254532Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e2896b-c2a9-4b98-c1e7-3e3880c13896"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "bL6zIZSt0h9W",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:07.256481Z",
          "iopub.execute_input": "2021-12-21T10:52:07.256820Z",
          "iopub.status.idle": "2021-12-21T10:52:07.263764Z",
          "shell.execute_reply.started": "2021-12-21T10:52:07.256781Z",
          "shell.execute_reply": "2021-12-21T10:52:07.261119Z"
        },
        "trusted": true
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "Vsxw4M2m0m2B",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:07.264772Z",
          "iopub.execute_input": "2021-12-21T10:52:07.265422Z",
          "iopub.status.idle": "2021-12-21T10:52:07.314184Z",
          "shell.execute_reply.started": "2021-12-21T10:52:07.265386Z",
          "shell.execute_reply": "2021-12-21T10:52:07.313523Z"
        },
        "trusted": true
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "metadata": {
        "id": "7rUTc0l60pV9",
        "outputId": "0db01aec-b0e6-41c7-b7ed-8df4170ddc34",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:52:07.315360Z",
          "iopub.execute_input": "2021-12-21T10:52:07.316122Z",
          "iopub.status.idle": "2021-12-21T10:57:26.378708Z",
          "shell.execute_reply.started": "2021-12-21T10:52:07.316087Z",
          "shell.execute_reply": "2021-12-21T10:57:26.377085Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:30<00:00, 1018.43it/s, train_loss=0.477]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.566, test - 0.466\n",
            "F1 test - 0.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:28<00:00, 1028.10it/s, train_loss=0.443]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.455, test - 0.445\n",
            "F1 test - 0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:27<00:00, 1030.59it/s, train_loss=0.421]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.428, test - 0.433\n",
            "F1 test - 0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:28<00:00, 1025.06it/s, train_loss=0.398]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.405, test - 0.434\n",
            "F1 test - 0.842\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ],
      "metadata": {
        "id": "1TMaPbh3oWwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for instance in list(tqdm._instances): \n",
        "    tqdm._decr_instances(instance)"
      ],
      "metadata": {
        "id": "_aPjTQcR0vm2",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:57:26.380063Z",
          "iopub.execute_input": "2021-12-21T10:57:26.380299Z",
          "iopub.status.idle": "2021-12-21T10:57:26.383925Z",
          "shell.execute_reply.started": "2021-12-21T10:57:26.380265Z",
          "shell.execute_reply": "2021-12-21T10:57:26.383273Z"
        },
        "trusted": true
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
      ],
      "metadata": {
        "id": "UbR_5B_80tJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_upgrade(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "        \n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(300, 256, \n",
        "                                  num_layers=2, bidirectional=True, dropout=0.1,\n",
        "                                  batch_first=True)\n",
        "        \n",
        "        self.q_proj = torch.nn.Linear(in_features=2*256, out_features=256, bias=True)\n",
        "        self.k_proj = torch.nn.Linear(in_features=2*256, out_features=256, bias=True)\n",
        "        self.v_proj = torch.nn.Linear(in_features=2*256, out_features=256, bias=True)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        \n",
        "        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
        "        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "\n",
        "        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n",
        "        self.relu = torch.nn.PReLU()\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "        self.dropout = torch.nn.Dropout(p=0.3)\n",
        "\n",
        "        \n",
        "  def forward(self, x):\n",
        "      x_emb = self.emb_layer(x) #примените эмбеддинги\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) / sqrt(x_q.size(-1))\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      \n",
        "      x =  self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.dropout(self.relu(x))    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ],
      "metadata": {
        "id": "e5BgHdtW2sO3",
        "execution": {
          "iopub.status.busy": "2021-12-21T10:57:26.385383Z",
          "iopub.execute_input": "2021-12-21T10:57:26.385972Z",
          "iopub.status.idle": "2021-12-21T10:57:26.403534Z",
          "shell.execute_reply.started": "2021-12-21T10:57:26.385936Z",
          "shell.execute_reply": "2021-12-21T10:57:26.402700Z"
        },
        "trusted": true
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_upgrade(vectors, n_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-21T10:57:26.404756Z",
          "iopub.execute_input": "2021-12-21T10:57:26.405113Z",
          "iopub.status.idle": "2021-12-21T10:57:26.553425Z",
          "shell.execute_reply.started": "2021-12-21T10:57:26.405080Z",
          "shell.execute_reply": "2021-12-21T10:57:26.552705Z"
        },
        "trusted": true,
        "id": "RuoE2hZP0tJ2"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-21T10:57:26.554820Z",
          "iopub.execute_input": "2021-12-21T10:57:26.555066Z",
          "iopub.status.idle": "2021-12-21T10:57:26.561279Z",
          "shell.execute_reply.started": "2021-12-21T10:57:26.555033Z",
          "shell.execute_reply": "2021-12-21T10:57:26.560537Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAMGIZqs0tJ3",
        "outputId": "987bf67d-6c4a-4839-bbdd-664cd5fe9a9d"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_upgrade(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): PReLU(num_parameters=1)\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-21T10:57:26.562540Z",
          "iopub.execute_input": "2021-12-21T10:57:26.562982Z",
          "iopub.status.idle": "2021-12-21T10:57:26.613442Z",
          "shell.execute_reply.started": "2021-12-21T10:57:26.562945Z",
          "shell.execute_reply": "2021-12-21T10:57:26.612829Z"
        },
        "trusted": true,
        "id": "RlKuphyn0tJ3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-21T10:57:26.614754Z",
          "iopub.execute_input": "2021-12-21T10:57:26.615013Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lZ6mBfA0tJ3",
        "outputId": "09ca936a-e6a8-4a79-b411-74a92a738e07"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:19<00:00, 1074.90it/s, train_loss=0.482]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.569, test - 0.470\n",
            "F1 test - 0.828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:22<00:00, 1058.27it/s, train_loss=0.448]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.460, test - 0.447\n",
            "F1 test - 0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:21<00:00, 1059.58it/s, train_loss=0.424]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.432, test - 0.436\n",
            "F1 test - 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:21<00:00, 1061.33it/s, train_loss=0.405]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.411, test - 0.430\n",
            "F1 test - 0.846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [03:21<00:00, 1063.53it/s, train_loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.390, test - 0.438\n",
            "F1 test - 0.845\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Результаты:**\n",
        "\n",
        "после добавления дропаут результат стал немного лучше\n",
        "\n",
        "функции активации пробовать не стала, бесполезно\n",
        "\n",
        "предобработка вообще все портила("
      ],
      "metadata": {
        "id": "S5jFdBAJTNhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "dZzEW31G0tJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euZqY84a0tJ3",
        "outputId": "a46f0d15-3f0f-4348-8511-5974c98a1f37"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = data.text.values\n",
        "labels = data.category.values"
      ],
      "metadata": {
        "trusted": true,
        "id": "kMCb6ZdE0tJ4"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('cointegrated/rubert-tiny', do_lower_case=True)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdUGu7xq0tJ4",
        "outputId": "1cf0d11a-f8cf-4a68-8924-0d0e2116fc73"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwVL0CTu0tJ4",
        "outputId": "d189069a-7129-43c4-fcc4-130dc8cb91c7"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Tokenized:  ['могут', 'ли', 'в', 'рос', '##сел', '##ь', '##хоз', '##бан', '##ке', 'да', '##ть', 'в', 'зал', '##ог', 'но', '##рко', '##вых', 'ш', '##уб', 'пом', '##оги', '##те', 'по', '##жал', '##уи', '##ста']\n",
            "Token IDs:  [6716, 10632, 314, 8918, 21665, 1090, 21244, 10934, 1550, 791, 1348, 314, 20839, 5054, 1363, 28299, 7546, 336, 12875, 26662, 20952, 988, 705, 9354, 25347, 3689]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "id": "sXqC692D0tJ4"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in tqdm(sentences):\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGMBQUh30tJ4",
        "outputId": "2b1d2384-a081-4780-a116-9d9dd328238b"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [02:39<00:00, 1492.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Token IDs: [2, 6716, 10632, 314, 8918, 21665, 1090, 21244, 10934, 1550, 791, 1348, 314, 20839, 5054, 1363, 28299, 7546, 336, 12875, 26662, 20952, 988, 705, 9354, 25347, 3689, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_9OLczr0tJ4",
        "outputId": "d7b42c9d-26e2-447e-ed40-ff2666eb5030"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 70\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLlEqWf10tJ4",
        "outputId": "1b58823a-ffbd-458d-9d6a-e2e0f8de86d2"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 70 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in tqdm(input_ids):\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBxTod5Z0tJ5",
        "outputId": "6dd0fc97-1546-4b4f-c58a-8b591be6542c"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:27<00:00, 8666.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "4o74_WjI0tJ5"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OWmgrHqu0tJ5"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vOkEV2hP0tJ5"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"cointegrated/rubert-tiny\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZudftYy0tJ5",
        "outputId": "314c7c3f-338d-4c2c-b3f0-f53d4a791704"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
              "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=312, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = model.bert.pooler.dense.weight\n",
        "c = model.classifier.weight\n",
        "b = b.cpu().detach().numpy()\n",
        "c = c.cpu().detach().numpy()"
      ],
      "metadata": {
        "trusted": true,
        "id": "hu4LHlS20tJ5"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6_nHJsd0tJ5",
        "outputId": "3db90e16-2fd7-499a-ea20-f8f9c4ddb34d"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 57 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (29564, 312)\n",
            "bert.embeddings.position_embeddings.weight                (512, 312)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 312)\n",
            "bert.embeddings.LayerNorm.weight                              (312,)\n",
            "bert.embeddings.LayerNorm.bias                                (312,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (312, 312)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (312,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (312, 312)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (312,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (312, 312)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (312,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (312, 312)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (312,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (312,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (312,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight            (600, 312)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                  (600,)\n",
            "bert.encoder.layer.0.output.dense.weight                  (312, 600)\n",
            "bert.encoder.layer.0.output.dense.bias                        (312,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (312,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (312,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (312, 312)\n",
            "bert.pooler.dense.bias                                        (312,)\n",
            "classifier.weight                                           (5, 312)\n",
            "classifier.bias                                                 (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "trusted": true,
        "id": "IIyKNZgx0tJ6"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 8\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "trusted": true,
        "id": "z0qLWERC0tJ6"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "# меняю на F-score, чтобы можно было сравнить\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(pred_flat, labels_flat, average='micro')"
      ],
      "metadata": {
        "trusted": true,
        "id": "pQAORD0V0tJ6"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "trusted": true,
        "id": "lf7bsOiw0tJ6"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5BE1nF20tJ6",
        "outputId": "f57d6fa3-b5b4-47c1-dbd2-9ba6e71e3fd6"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:08.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:22.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:48.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:52.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:56.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:00:59.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:03.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:07.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:11.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:14.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:18.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:23.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:26.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:34.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:38.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:41.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:45.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:49.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:52.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:56.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:02:00.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:03.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:07.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:11.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:15.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:18.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:22.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:26.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:30.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:34.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:38.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:42.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:45.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:49.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:53.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:02:56.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:03:00.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:04.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:11.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:15.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:19.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:22.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:26.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:33.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:37.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:41.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:45.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:48.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:03:52.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:03:56.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:03:59.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:03.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:07.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:11.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:14.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:18.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:22.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:25.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:29.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:33.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:37.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:04:44.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:04:48.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:04:51.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:04:55.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:04:59.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:06.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:10.\n",
            "\n",
            "  Average training loss: 0.75\n",
            "  Training epcoh took: 0:05:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 2 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:07.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:22.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:33.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:48.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:52.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:56.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:00:59.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:03.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:07.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:10.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:14.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:18.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:21.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:25.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:37.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:42.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:45.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:49.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:53.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:56.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:02:00.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:04.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:08.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:11.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:15.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:19.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:23.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:26.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:30.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:34.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:37.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:41.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:45.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:49.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:52.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:02:56.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:03:00.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:03.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:11.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:15.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:18.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:22.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:26.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:29.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:33.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:37.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:41.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:44.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:48.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:03:52.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:03:55.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:04:00.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:04.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:07.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:11.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:15.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:18.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:22.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:26.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:30.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:33.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:37.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:04:41.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:04:44.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:04:48.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:04:52.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:04:56.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:04:59.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:03.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:07.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:10.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:05:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 3 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:07.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:22.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:49.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:54.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:58.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:01:02.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:06.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:11.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:14.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:18.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:22.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:25.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:29.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:37.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:40.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:44.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:48.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:52.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:55.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:59.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:02:03.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:06.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:10.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:14.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:18.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:21.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:25.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:29.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:32.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:36.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:40.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:44.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:47.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:51.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:55.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:02:59.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:03:02.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:06.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:10.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:14.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:17.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:21.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:25.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:29.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:34.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:39.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:43.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:48.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:52.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:57.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:04:01.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:04:06.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:04:11.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:15.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:20.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:24.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:29.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:34.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:38.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:42.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:47.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:51.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:56.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:05:00.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:05:05.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:05:08.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:05:12.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:05:16.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:05:20.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:23.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:27.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:31.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:05:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 4 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:07.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:49.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:52.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:56.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:01:00.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:03.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:07.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:11.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:15.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:19.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:22.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:26.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:34.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:37.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:41.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:45.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:48.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:52.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:56.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:02:00.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:04.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:08.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:12.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:15.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:19.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:23.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:27.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:30.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:34.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:38.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:42.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:45.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:49.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:53.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:02:57.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:03:01.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:05.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:08.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:12.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:16.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:19.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:23.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:27.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:34.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:38.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:42.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:45.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:49.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:03:57.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:04:00.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:04.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:08.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:12.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:15.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:19.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:23.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:27.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:30.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:34.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:38.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:04:42.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:04:45.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:04:49.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:04:53.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:04:57.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:05:00.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:04.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:08.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:12.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:05:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 5 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:07.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:22.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:48.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:52.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:57.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:01:01.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:05.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:09.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:12.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:16.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:20.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:24.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:28.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:32.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:36.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:40.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:44.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:48.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:51.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:55.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:59.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:02:03.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:07.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:11.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:15.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:18.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:22.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:26.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:30.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:33.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:37.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:41.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:45.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:48.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:52.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:56.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:03:00.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:03:03.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:11.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:15.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:18.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:22.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:26.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:33.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:37.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:41.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:45.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:50.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:03:57.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:04:01.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:04:05.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:08.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:12.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:20.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:23.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:27.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:31.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:35.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:38.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:42.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:04:46.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:04:50.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:04:53.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:04:57.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:05:01.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:05:05.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:08.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:12.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:16.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:05:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 6 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:08.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:23.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:49.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:52.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:56.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:01:00.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:05.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:08.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:12.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:16.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:20.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:23.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:27.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:31.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:35.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:38.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:42.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:46.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:50.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:53.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:57.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:02:01.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:05.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:08.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:12.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:16.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:20.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:23.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:27.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:31.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:35.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:38.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:42.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:46.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:50.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:53.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:02:57.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:03:01.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:04.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:08.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:12.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:16.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:19.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:23.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:27.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:30.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:34.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:38.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:42.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:45.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:49.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:03:57.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:04:01.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:05.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:09.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:12.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:20.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:24.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:27.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:31.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:35.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:38.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:04:42.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:04:46.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:04:50.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:04:53.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:04:57.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:05:01.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:05.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:08.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:12.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:05:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 7 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:07.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:22.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:48.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:52.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:56.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:01:00.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:03.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:07.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:11.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:14.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:18.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:22.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:26.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:37.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:40.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:44.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:48.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:52.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:55.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:01:59.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:03.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:07.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:10.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:14.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:18.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:22.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:26.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:30.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:34.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:37.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:41.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:45.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:48.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:52.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:02:56.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:03:00.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:03.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:07.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:11.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:14.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:18.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:22.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:25.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:29.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:33.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:37.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:40.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:44.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:48.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:03:51.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:03:55.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:03:59.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:02.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:06.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:10.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:14.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:17.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:21.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:25.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:28.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:32.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:36.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:04:40.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:04:43.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:04:47.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:04:51.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:04:54.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:04:58.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:02.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:05.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:09.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:05:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 8 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:00:07.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:00:22.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:00:26.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:00:30.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:00:37.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:00:41.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:00:45.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:00:48.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:00:52.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:00:56.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:01:00.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:01:03.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:01:07.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:01:11.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:01:14.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:01:18.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:01:22.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:01:26.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:01:33.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:01:37.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:01:40.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:01:44.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:01:48.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:01:52.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:01:55.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:01:59.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:02:03.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:02:06.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:02:10.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:02:14.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:02:17.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:02:21.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:02:25.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:02:29.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:02:32.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:02:36.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:02:40.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:02:43.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:02:47.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:02:51.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:02:54.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:02:58.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:03:02.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:03:06.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:03:09.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:03:13.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:03:17.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:03:20.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:03:24.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:03:28.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:03:32.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:03:35.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:03:39.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:03:43.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:03:46.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:03:50.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:03:54.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:03:57.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:04:01.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:04:05.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:04:09.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:04:12.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:04:16.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:04:20.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:04:23.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:04:27.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:04:31.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:04:35.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:04:38.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:04:42.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:04:46.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:04:49.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:04:53.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:04:57.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:05:00.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:05:04.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:05:08.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:05:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучала сначала на моделе побольше, но все слетело\n",
        "\n",
        "Результаты, даже на rubert tiny, вышли в целом сравнимые, но берт чуть хуже\n",
        "\n",
        "Правда после 4 эпохи результаты перестали меняться, можно было и 4 оставить"
      ],
      "metadata": {
        "id": "WobMNtOEW2ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OsdJsRMPYIzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}